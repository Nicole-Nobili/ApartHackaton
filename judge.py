import goodfire
from typing import List
import re
import openai
from prompts import (
    JUDGE_SYSTEM_PROMPT,
)
from custom_decorators import deprecated

#TODO: implement openAI judge
class Judge:
    @classmethod #TODO debug
    def from_goodfire(cls, client: goodfire.Client, variant: str):
        """Create a Retriever from a GoodFire client.

        Args:
            client (goodfire.Client): the GoodFire client
            variant (str): model name to use for both the prompter and feature searcher
        """
        assert isinstance(client, goodfire.Client), "client must be a goodfire.Client"
        assert isinstance(variant, str), "variant must be a string"
        
        self = cls.__new__(cls)
        self.client = client
        self.variant = goodfire.Variant(variant)
        self.SYS_PROMPT = JUDGE_SYSTEM_PROMPT
        return self
    
    @classmethod #TODO debug
    def from_openAI(cls, client: openai.Client, variant: str):
        """Create a Retriever from a GoodFire client.

        Args:
            client (goodfire.Client): the GoodFire client
            variant (str): model name to use for both the prompter and feature searcher
        """
        raise NotImplementedError("OpenAI judge is not implemented yet")
        assert isinstance(prompter, openai.Client), "prompter must be an openai.Client"
        assert isinstance(prompter_variant, str), "prompter_variant must be a string"
        assert isinstance(feature_searcher, goodfire.Client), "feature_searcher must be a goodfire.Client"
        assert isinstance(feature_searcher_variant, str), "feature_searcher_variant must be a string"
        
        self = cls.__new__(cls)
        self.system_prompt = RETRIEVER_SYSTEM_PROMPT
        self.prompter = prompter
        self.prompter_variant = prompter_variant
        self.feature_searcher = feature_searcher
        self.feature_searcher_variant = goodfire.Variant(feature_searcher_variant)
        return self
    
    @deprecated #TODO this should not be like this !!!
    def __init__(self, client: goodfire.Client, variant: str):
        self.client = client
        if isinstance(client, goodfire.Client):
            self.variant = goodfire.Variant(variant)
        else:
            self.variant = variant

        self.SYS_PROMPT = JUDGE_SYSTEM_PROMPT
        
    def judge_output(self, target_behavior: str, steered_model_output: str, steered_model_input: str):
        """Judge a steered model output against a target behavior.

        Args:
            target_behavior (str): The desired behavior to evaluate against
            steered_model_output (str): The output generated by the steered model
            steered_model_input (str): The input provided to the steered model
                (Can be a list of various inputs and outputs)

        Returns:
            str: A free-text critique evaluating how well the steered output
                matches the target behavior given the input
        """
        #maybe look at textgrad loss?
        completion = ""
        for token in self.client.chat.completions.create(
            [
                {"role": "system", "content": self.SYS_PROMPT},
                {"role": "user", "content": f"""Input prompt:\n{steered_model_input}\n\nResponse:\n{steered_model_output}\n\nTarget Behavior:{target_behavior}\n\n"""}
            ],
            model=self.variant,
            stream=True,
            max_completion_tokens=200,
        ):
            completion += token.choices[0].delta.content
        return completion

    @deprecated
    def judge_output_deprecated(
        self, target_behavior: str, steered_model_output: str, steered_model_input: str
    ):
        """Judge a steered model output against a target behavior.

        Args:
            target_behavior (str): The desired behavior to evaluate against
            steered_model_output (str): The output generated by the steered model
            steered_model_input (str): The input provided to the steered model
                (Can be a list of various inputs and outputs)

        Returns:
            str: A free-text critique evaluating how well the steered output
                matches the target behavior given the input
        """
        # maybe look at textgrad loss?
        completion = self.client.chat.completions.create(
            messages=[
                {"role": "system", "content": self.SYS_PROMPT},
                {
                    "role": "user",
                    "content": f"""Input prompt:\n{steered_model_input}\n\nResponse:\n{steered_model_output}\n\nTarget Behavior:{target_behavior}\n\n""",
                },
            ],
            model=self.variant,
            # stream=True,
            # max_completion_tokens=200,
        )

        if isinstance(self.client, goodfire.Client):
            return completion.choices[0].message["content"]
        else:
            return completion.choices[0].message.content